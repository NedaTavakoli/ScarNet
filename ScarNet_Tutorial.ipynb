{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30781a3e",
   "metadata": {},
   "source": [
    "# ScarNet Tutorial\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NedaTavakoli/ScarNet/blob/main/examples/ScarNet_Tutorial.ipynb)\n",
    "\n",
    "This notebook demonstrates how to use ScarNet for cardiac scar segmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7dcd85",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's install the required packages and clone the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchvision h5py matplotlib tqdm scikit-learn\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/NedaTavakoli/ScarNet.git\n",
    "!cd ScarNet && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scarnet.models.scarnet import ScarNet\n",
    "from scarnet.data.dataset import CardiacDataset\n",
    "from scarnet.utils.visualization import Visualizer\n",
    "from scarnet.config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd0b20",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bc390",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Let's prepare a small dataset for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, we'll use a small subset of data\n",
    "data_path = Path('ScarNet/data')\n",
    "\n",
    "# Create dataset\n",
    "dataset = CardiacDataset(\n",
    "    x_files=sorted(data_path.glob('**/Mag_image/*.h5'))[:5],  # Use 5 samples\n",
    "    y_files=[Path(str(x).replace('Mag_image', '4layer_mask')) \n",
    "             for x in sorted(data_path.glob('**/Mag_image/*.h5'))[:5]],\n",
    "    imsize=128,\n",
    "    augment=True,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc78e57",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ScarNet(\n",
    "    pretrained_path='ScarNet/weights/medsam_vit_b.pth',\n",
    "    num_classes=4\n",
    ").to(device)\n",
    "\n",
    "# Load pretrained weights if available\n",
    "checkpoint_path = 'ScarNet/weights/scarnet_best.pth'\n",
    "if Path(checkpoint_path).exists():\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print('Loaded pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89238879",
   "metadata": {},
   "source": [
    "## Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07358f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader=None, epochs=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    best_dice = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            image = batch['image'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(image)\n",
    "            loss = criterion(output, mask.squeeze(1))\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "# Uncomment to train\n",
    "# train_model(model, loader)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
